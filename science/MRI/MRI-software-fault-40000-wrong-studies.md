# Software faults raise questions about the validity of brain studies 
[Software faults raise questions about the validity of brain studies | Ars Technica](https://arstechnica.com/science/2016/07/algorithms-used-to-study-brain-activity-may-be-exaggerating-results/)

the cluster identification algorithms frequently assign activity to a region when none is likely to be present. How frequently? Up to 70 percent of the time, depending on the algorithm and parameters used.

For good measure, a bug that has been sitting in the code for 15 years showed up during this testing. The fix for the bug reduced false positives by more than 10 percent. While good that it's fixed, it's a shame that all those studies have been published using the faulty version.

The authors also found that some regions of the brain were more likely to have problems with false positives possibly because of assumptions the algorithms make about the underlying brain morphology.

Is this really as bad as it sounds? The authors certainly think so. "This calls into question the validity of countless published fMRI studies based on parametric clusterwise inference." It's not clear how many of those there are, but they're likely to be a notable fraction of the total number of studies that use fMRI, which the authors estimate at 40,000.
